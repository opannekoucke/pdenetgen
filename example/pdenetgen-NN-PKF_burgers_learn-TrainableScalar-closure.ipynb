{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center> Training of a closure designed with `TrainableScalar` for the PKF applied to the Burgers dynamics </center></h1>\n",
    "<center>\n",
    "    Olivier Pannekoucke <br> 2020\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "The aim is to train a closure to predict the uncertainty dynamics for the Burgers dynamics.\n",
    "\n",
    "The notebook present the situation where uknown physical processes are represented by a symbolic expression where `TrainableScalar` are used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "---\n",
    "<center> <b>Table of contents</b> </center>\n",
    "\n",
    " 1. [Introduction](#introduction)\n",
    " 1. [The Burgers dynamics](#the-burgers-dynamics)\n",
    " 1. [PKF for the Burgers dynamics](#pkf-forthe-burgers-dynamics)\n",
    " 1. [Numerical application](#numerical-application)\n",
    "   - [Generation of a database](#generation-of-a-database)\n",
    "   - [Training of the closure](#training-of-the-closure)\n",
    "   - [Comparison with the theoretically designed closure](#comparison-with-the-theoretically-designed-closure)\n",
    " 1. [Conclusion](#conclusion)\n",
    " ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-29T13:49:35.003934Z",
     "start_time": "2018-11-29T13:49:34.831778Z"
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction <a id='introduction'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim is to design a NN which merges known and unknown physics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-03T09:05:22.911943Z",
     "start_time": "2018-10-03T09:05:22.699109Z"
    }
   },
   "outputs": [],
   "source": [
    "import sympy\n",
    "from sympy import (Function, symbols, init_printing, Derivative, \n",
    "                   latex, Add, Mul, Pow, \n",
    "                   Integer, Rational, Float, Symbol,\n",
    "                   srepr, Tuple\n",
    "                  )\n",
    "init_printing() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Burgers dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdenetgen import NNModelBuilder, Eq\n",
    "import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_system(system):\n",
    "    print(50*'*')\n",
    "    for equation in system:\n",
    "        display(equation)\n",
    "        print(50*'*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set of the function and symbols <a id='burgers-pkf-sympy-definition'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdenetgen import t\n",
    "x = symbols('x')\n",
    "\n",
    "u = Function('u')(t,x)\n",
    "closure = sympy.Function('closure')(t,x)\n",
    "V = Function('{V_{u}}')(t,x)\n",
    "nu = Function('{\\\\nu_{u,xx}}')(t,x)\n",
    "Kappa = symbols('\\\\kappa')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set constants for numerical experiments <a id='burgers-pkf-num-definition'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constant setting following Pannekoucke et al. (2018)\n",
    "n = 241\n",
    "kappa = 0.0025\n",
    "dt = 0.002"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set of the Burgers equation <a id='burgers-pkf-dyn-burgers'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/latex": [
       "$\\displaystyle \\frac{\\partial}{\\partial t} u{\\left(t,x \\right)} = \\kappa \\frac{\\partial^{2}}{\\partial x^{2}} u{\\left(t,x \\right)} - u{\\left(t,x \\right)} \\frac{\\partial}{\\partial x} u{\\left(t,x \\right)}$"
      ],
      "text/plain": [
       "                       2                               \n",
       "∂                     ∂                     ∂          \n",
       "──(u(t, x)) = \\kappa⋅───(u(t, x)) - u(t, x)⋅──(u(t, x))\n",
       "∂t                     2                    ∂x         \n",
       "                     ∂x                                "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n"
     ]
    }
   ],
   "source": [
    "burgers_dynamics = [\n",
    "        Eq(\n",
    "        Derivative(u,t),\n",
    "        Kappa*Derivative(u,x,2)-u*Derivative(u,x)\n",
    "      ),\n",
    "]\n",
    "display_system(burgers_dynamics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "burgers_NN_builder = NNModelBuilder(burgers_dynamics, \"Burgers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('input_shape_x', 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "burgers_NN_builder.prognostic_functions[0].input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class Burgers has been written in module burgers in file burgers.py\n"
     ]
    }
   ],
   "source": [
    "burgers_NN_builder.write_module()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from pdenetgen.model import Model\n",
      "import numpy as np\n",
      "import tensorflow.keras as keras\n",
      "from pdenetgen.symbolic.nn_builder import DerivativeFactory, TrainableScalarLayerFactory\n",
      "\n",
      "class Burgers(Model):\n",
      "\n",
      "    # Prognostic functions (sympy functions):\n",
      "    prognostic_functions = (\n",
      "            'u',    # Write comments on the function here\n",
      "        )\n",
      "\n",
      "    \n",
      "    \n",
      "    # Spatial coordinates\n",
      "    coordinates = (\n",
      "            'x',    # Write comments on the coordinate here\n",
      "        )\n",
      "\n",
      "    \n",
      "\n",
      "    \n",
      "    # Set constants\n",
      "    constants = (\n",
      "            'kappa',    # Writes comment on the constant here\n",
      "        )\n",
      "    \n",
      "\n",
      "    def __init__(self, shape=None, lengths=None, **kwargs):\n",
      "\n",
      "        super().__init__() # Time scheme is set from Model.__init__()\n",
      "                \n",
      "        #---------------------------------\n",
      "        # Set index array from coordinates\n",
      "        #---------------------------------\n",
      "        \n",
      "        # a) Set shape\n",
      "        shape = len(self.coordinates)*(100,) if shape is None else shape \n",
      "        if len(shape)!=len(self.coordinates):\n",
      "            raise ValueError(f\"len(shape) {len(shape)} is different from len(coordinates) {len(self.coordinates)}\")\n",
      "        else:\n",
      "            self.shape = shape\n",
      "    \n",
      "        # b) Set input shape for coordinates\n",
      "        self.input_shape_x = shape[0]\n",
      "        \n",
      "                \n",
      "        # c) Set lengths\n",
      "        lengths = len(self.coordinates)*(1.0,) if lengths is None else lengths\n",
      "        if len(lengths)!=len(self.coordinates):\n",
      "            raise ValueError(f\"len(lengths) {len(lengths)} is different from len(coordinates) {len(self.coordinates)}\")        \n",
      "        else:\n",
      "            self.lengths = lengths\n",
      "            \n",
      "        # d) Set indexes\n",
      "        self._index = {}\n",
      "        for k,coord in enumerate(self.coordinates):\n",
      "            self._index[(coord,0)] = np.arange(self.shape[k], dtype=int)            \n",
      "        \n",
      "        # Set x/dx\n",
      "        #-------------\n",
      "        self.dx = tuple(length/shape for length, shape in zip(self.lengths, self.shape))\n",
      "        self.x = tuple(self.index(coord,0)*dx for coord, dx in zip(self.coordinates, self.dx))\n",
      "        self.X = np.meshgrid(*self.x)\n",
      "\n",
      "        \n",
      "\n",
      "        \n",
      "        #---------------------------\n",
      "        # Set constants of the model\n",
      "        #---------------------------\n",
      "          \n",
      "        # Set a default nan value for constants\n",
      "        self.kappa = np.nan # @@ set constant value @@\n",
      "        \n",
      "                \n",
      "        # Set constant values from external **kwargs (when provided)\n",
      "        for key in kwargs:\n",
      "            if key in self.constants:\n",
      "                setattr(self, key, kwargs[key])\n",
      "        \n",
      "        # Alert when a constant is np.nan\n",
      "        for constant in self.constants:\n",
      "            if getattr(self, constant) is np.nan:\n",
      "                print(f\"Warning: constant `{constant}` has to be set\")\n",
      "        \n",
      "        \n",
      "        # Set NN models\n",
      "        self._trend_model = None\n",
      "        self._exogenous_model = None\n",
      "    \n",
      "    def index(self, coord, step:int):\n",
      "        \"\"\" Return int array of shift index associated with coordinate `coord` for shift `step` \"\"\"\n",
      "        # In this implementation, indexes are memory saved in a dictionary, feed at runtime \n",
      "        if (coord,step) not in self._index:\n",
      "            self._index[(coord,step)] = (self._index[(coord,0)]+step)%self.shape[self.coordinates.index(coord)]\n",
      "        return self._index[(coord,step)] \n",
      "    \n",
      "    def _make_trend_model(self):\n",
      "        \"\"\" Generate the NN used to compute the trend of the dynamics \"\"\"\n",
      "                        \n",
      "        # Alias for constants\n",
      "        #--------------------\n",
      "        kappa = self.kappa\n",
      "        if kappa is np.nan:\n",
      "            raise ValueError(\"Constant 'kappa' is not set\")\n",
      "                 \n",
      "                \n",
      "        \n",
      "        # Set input layers\n",
      "        #------------------\n",
      "        # Set Alias for coordinate input shapes\n",
      "        input_shape_x = self.input_shape_x\n",
      "                \n",
      "        # Set input shape for prognostic functions\n",
      "        u = keras.layers.Input(shape =(input_shape_x,1,))\n",
      "         \n",
      "                \n",
      "        \n",
      "         \n",
      "        # Keras code\n",
      "         \n",
      "        # 2) Implementation of derivative as ConvNet\n",
      "        # Compute derivative\n",
      "        #-----------------------\n",
      "        #\n",
      "        #  Warning: might be modified to fit appropriate boundary conditions. \n",
      "        #\n",
      "        kernel_Du_x_o1 = np.asarray([-1/(2*self.dx[self.coordinates.index('x')]),0.0,\n",
      "        1/(2*self.dx[self.coordinates.index('x')])]).reshape((3,)+(1,1))\n",
      "        Du_x_o1 = DerivativeFactory((3,),kernel=kernel_Du_x_o1,name='Du_x_o1')(u)\n",
      "        \n",
      "        kernel_Du_x_o2 = np.asarray([self.dx[self.coordinates.index('x')]**(-2),\n",
      "        -2/self.dx[self.coordinates.index('x')]**2,\n",
      "        self.dx[self.coordinates.index('x')]**(-2)]).reshape((3,)+(1,1))\n",
      "        Du_x_o2 = DerivativeFactory((3,),kernel=kernel_Du_x_o2,name='Du_x_o2')(u)\n",
      "        \n",
      "                \n",
      "        \n",
      "        # 3) Implementation of the trend as NNet\n",
      "        \n",
      "        #\n",
      "        # Computation of trend_u\n",
      "        #\n",
      "        sc_mul_0 = keras.layers.Lambda(lambda x: kappa*x,name='ScalarMulLayer_0')(Du_x_o2)\n",
      "        mul_0 = keras.layers.multiply([Du_x_o1,u],name='MulLayer_0')\n",
      "        sc_mul_1 = keras.layers.Lambda(lambda x: -1.0*x,name='ScalarMulLayer_1')(mul_0)\n",
      "        trend_u = keras.layers.add([sc_mul_0,sc_mul_1],name='AddLayer_0')\n",
      "        \n",
      "        \n",
      "        # 4) Set 'input' of model\n",
      "        inputs = [\n",
      "                # Prognostic functions\n",
      "                u,\n",
      "                \n",
      "            ]         \n",
      "   \n",
      "        # 5) Set 'outputs' of model \n",
      "        outputs = [\n",
      "            trend_u,\n",
      "            ]     \n",
      "        \n",
      "        model = keras.models.Model(inputs=inputs, outputs=outputs)\n",
      "        #model.trainable = False\n",
      "        self._trend_model = model\n",
      "        \n",
      "    def trend(self, t, state):\n",
      "        \"\"\" Trend of the dynamics \"\"\"\n",
      "        \n",
      "        if self._trend_model is None:\n",
      "            self._make_trend_model()\n",
      "\n",
      "        # Init output state with pointer on data\n",
      "        #-------------------------------------------\n",
      "\n",
      "        #   a) Set the output array\n",
      "        dstate = np.zeros(state.shape)\n",
      "\n",
      "        #   b) Set pointers on output array `dstate` for the computation of the physical trend (alias only).\n",
      "        du = dstate[0]\n",
      "        \n",
      "\n",
      "        # Load physical functions from state\n",
      "        #------------------------------------\n",
      "        u = state[0]\n",
      "                  \n",
      "         \n",
      "        \n",
      "        \n",
      "        # Compute the trend value from model.predict\n",
      "        #-------------------------------------------  \n",
      "        inputs = [\n",
      "            # Prognostic functions\n",
      "                u,\n",
      "                ]\n",
      "        \n",
      "        dstate = self._trend_model.predict( inputs )\n",
      "        \n",
      "        if not isinstance(dstate,list):\n",
      "            dstate = [dstate]\n",
      "        \n",
      "        return np.array(dstate)\n",
      "        \n",
      "    \n",
      "    def _make_dynamical_trend(self):\n",
      "        \"\"\"\n",
      "        Computation of a trend model so to be used in a time scheme (as solving a dynamical system or an ODE)\n",
      "        \n",
      "        Description:\n",
      "        ------------\n",
      "        \n",
      "        In the present implementation, the inputs of the trend `self._trend_model` is a list of fields, while\n",
      "        entry of a time-scheme is a single array which contains all fields.\n",
      "        \n",
      "        The aims of `self._dynamical_trend` is to produce a Keras model which:\n",
      "        1. takes a single array as input\n",
      "        2. extract the `self._trend_model` input list from the input array\n",
      "        3. compute the trends from `self._trend_model`\n",
      "        4. outputs the trends as a single array\n",
      "        \n",
      "        Explaination of the code:\n",
      "        -------------------------\n",
      "        \n",
      "        Should implement a code as the following, that is valid for the PKF-Burgers         \n",
      "                \n",
      "        def _make_dynamical_trend(self):\n",
      "\n",
      "            if self._trend_model is None:\n",
      "                self._make_trend_model()\n",
      "\n",
      "            # 1. Extract the input of the model\n",
      "            \n",
      "            # 1.1 Set the input as an array\n",
      "            state = keras.layers.Input(shape=(3,self.input_shape_x,1))\n",
      "\n",
      "            # 1.2 Extract each components of the state\n",
      "            u = keras.layers.Lambda(lambda x : x[:,0,:,:])(state)\n",
      "            V = keras.layers.Lambda(lambda x : x[:,1,:,:])(state)\n",
      "            nu_u_xx = keras.layers.Lambda(lambda x : x[:,2,:,:])(state)\n",
      "\n",
      "            # 2. Compute the trend\n",
      "            trend_u, trend_V, trend_nu = self._trend_model([u,V,nu_u_xx])\n",
      "            \n",
      "            # 3. Outputs the trend as a single array\n",
      "\n",
      "            # 3.1 Reshape trends\n",
      "            trend_u = keras.layers.Reshape((1,self.input_shape_x,1))(trend_u)\n",
      "            trend_V = keras.layers.Reshape((1,self.input_shape_x,1))(trend_V)\n",
      "            trend_nu = keras.layers.Reshape((1,self.input_shape_x,1))(trend_nu)\n",
      "                        \n",
      "            # 3.2 Concatenates all trends\n",
      "            trends = keras.layers.Concatenate(axis=1)([trend_u,trend_V,trend_nu])\n",
      "            \n",
      "            # 4. Set the dynamical_trend model\n",
      "            self._dynamical_trend = keras.models.Model(inputs=state,outputs=trends)        \n",
      "        \"\"\"\n",
      "        \n",
      "        \n",
      "        if self._trend_model is None:            \n",
      "            self._make_trend_model()\n",
      "            \n",
      "            \n",
      "        for exclude_case in ['constant_functions','exogenous_functions']:\n",
      "            if hasattr(self,exclude_case):\n",
      "                raise NotImplementedError(f'Design of dynamical_model with {exclude_case} is not implemented')\n",
      "\n",
      "                \n",
      "        # Case 1 --  corresponds to the _trend_model if input is a single field                        \n",
      "        if not isinstance(self._trend_model.input_shape, list):\n",
      "            self._dynamical_trend = self._trend_model\n",
      "            return\n",
      "\n",
      "        # Case 2 -- Case where multiple list is used\n",
      "        \n",
      "        # 1. Extract the input of the model\n",
      "\n",
      "        # 1.1 Set the input as an array\n",
      "        \"\"\" from PKF-Burgers code:\n",
      "        state = keras.layers.Input(shape=(3,self.input_shape_x,1))\n",
      "        \"\"\"\n",
      "        \n",
      "        # 1.1.1 Compute the input_shape from _trend_model\n",
      "        shapes = []\n",
      "        dimensions  = []\n",
      "        for shape in self._trend_model.input_shape:\n",
      "            shape = shape[1:] # Exclude batch_size (assumed to be at first)\n",
      "            shapes.append(shape)\n",
      "            dimensions.append(len(shape)-1)\n",
      "            \n",
      "        max_dimension = max(dimensions)\n",
      "        if max_dimension!=1:\n",
      "            if 1 in dimensions:\n",
      "                raise NotImplementedError('1D fields incompatible with 2D/3D fields')            \n",
      "\n",
      "        # todo: add test to check compatibility of shapes!!!!\n",
      "        \n",
      "        if max_dimension in [1,2]:\n",
      "            input_shape = (len(shapes),)+shapes[0]\n",
      "        elif max_dimension==3:\n",
      "            \n",
      "            # a. check the size of 2D fields: this is given by the first 2D field.\n",
      "            for shape, dimension in zip(shapes, dimensions):\n",
      "                if dimension==2:\n",
      "                    input_shape_2D = shape\n",
      "                    break\n",
      "                    \n",
      "            # b. Compute the numbers of 2D fields: this corresponds to the number of 3D layers and the number of 2D fields.\n",
      "        \n",
      "            for shape, dimension in zip(shapes, dimensions):\n",
      "                if dimension==2:\n",
      "                    nb_outputs += 1\n",
      "                else:\n",
      "                    nb_outputs += shape[0]\n",
      "                    \n",
      "            input_shape = (nb_outputs,)+input_shape_2D\n",
      "            \n",
      "        # 1.1.2 Init the state of the dynamical_trend\n",
      "        state = keras.layers.Input(shape=input_shape)\n",
      "        \n",
      "        # 1.2 Extract each components of the state\n",
      "        \"\"\" From PKF-Burgers code:\n",
      "        \n",
      "        u = keras.layers.Lambda(lambda x : x[:,0,:,:])(state)\n",
      "        V = keras.layers.Lambda(lambda x : x[:,1,:,:])(state)\n",
      "        nu_u_xx = keras.layers.Lambda(lambda x : x[:,2,:,:])(state)\n",
      "        \n",
      "        inputs = [u, V, nu_u_xx]\n",
      "        \"\"\"\n",
      "\n",
      "        def get_slice(dimension, k):\n",
      "            def func(x):\n",
      "                if dimension == 1:\n",
      "                    return x[:,k,:,:]\n",
      "                elif dimension == 2:\n",
      "                    return x[:,k,:,:]\n",
      "            return func\n",
      "            \n",
      "        def get_slice_3d(start,end):\n",
      "            def func(x):\n",
      "                return x[:,start:end,:,:,:]\n",
      "            return func\n",
      "\n",
      "        inputs = []\n",
      "        if max_dimension in [1,2]:\n",
      "            for k in range(len(shapes)):\n",
      "                inputs.append(keras.layers.Lambda(get_slice(max_dimension,k))(state))\n",
      "                #if max_dimension==1:\n",
      "                #    inputs.append(keras.layers.Lambda(lambda x : x[:,k,:,:])(state))\n",
      "                #\n",
      "                #if max_dimension==2:\n",
      "                #    inputs.append(keras.layers.Lambda(lambda x : x[:,k,:,:,:])(state))                    \n",
      "        else:\n",
      "            k=0\n",
      "            for shape, dimension in zip(shapes, dimensions):\n",
      "                if dimension==2:\n",
      "                    #inputs.append(keras.layers.Lambda(lambda x : x[:,k,:,:,:])(state))\n",
      "                    inputs.append(keras.layers.Lambda(get_slice(dimension,k))(state))\n",
      "                    k += 1 \n",
      "                if dimension==3:\n",
      "                    start = k\n",
      "                    end = start+shape[0]\n",
      "                    inputs.append(keras.layers.Lambda(get_slice_3d(start,end))(state))\n",
      "                    k = end\n",
      "                    \n",
      "        # 2. Compute the trend\n",
      "        \"\"\" From PKF-Burgers code\n",
      "        trend_u, trend_V, trend_nu = self._trend_model([u,V,nu_u_xx])\n",
      "        \"\"\"\n",
      "        trends = self._trend_model(inputs)\n",
      "        \n",
      "        # 3. Outputs the trend as a single array\n",
      "\n",
      "        # 3.1 Reshape trends\n",
      "        \"\"\" from PKF-Burgers code\n",
      "        trend_u = keras.layers.Reshape((1,self.input_shape_x,1))(trend_u)\n",
      "        trend_V = keras.layers.Reshape((1,self.input_shape_x,1))(trend_V)\n",
      "        trend_nu = keras.layers.Reshape((1,self.input_shape_x,1))(trend_nu)\n",
      "        \"\"\"\n",
      "        \n",
      "        reshape_trends = [] \n",
      "        for trend, dimension in zip(trends, dimensions):\n",
      "            \n",
      "            #shape = tuple(dim.value for dim in trend.shape[1:])\n",
      "            # update from keras -> tensorflow.keras\n",
      "            shape = tuple(dim for dim in trend.shape[1:])\n",
      "            \n",
      "            if dimension==1 or dimension==2:\n",
      "                # for 1D fields like (128,1) transform into (1,128,1)\n",
      "                # for 2D fields like (128,128,1) transform into (1,128,128,1)\n",
      "                shape = (1,)+shape\n",
      "            elif dimension==3:\n",
      "                # 3D fields can be compated: two fields (36,128,128,1) become the single field (72,128,128,1)\n",
      "                pass\n",
      "            else:\n",
      "                raise NotImplementedError\n",
      "                \n",
      "            reshape_trends.append(keras.layers.Reshape(shape)(trend))\n",
      "        \n",
      "        # 3.2 Concatenates all trends\n",
      "        \"\"\" From PKF-Burgers code:\n",
      "        trends = keras.layers.Concatenate(axis=1)([trend_u,trend_V,trend_nu])\n",
      "        \"\"\"\n",
      "        trends = keras.layers.Concatenate(axis=1)(reshape_trends)\n",
      "        \n",
      "        # 2.5 Compute the model       \n",
      "        self._dynamical_trend = keras.models.Model(inputs=state,outputs=trends)    \n",
      "                \n",
      "    \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(burgers_NN_builder.code)\n",
    "exec(burgers_NN_builder.code)\n",
    "burgers = Burgers(shape=(n,), kappa=kappa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Example of forecast from a given initial condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_results(data, label=None, labelx=True, title=None, save_file=None, normalisation=None, \n",
    "                 selected_times=None,style=None, name=None, alpha=1., bolds=[0., 1.]):\n",
    "    \n",
    "    normalisation = 1. if normalisation is None else normalisation\n",
    "                 \n",
    "    selected_times = [time for time in data] if selected_times is None else selected_times\n",
    "                 \n",
    "    style = 'k' if style is None else style\n",
    "                 \n",
    "    for time in selected_times:\n",
    "        lalpha = alpha if time in bolds else 0.2\n",
    "        lname = name if time==selected_times[-1] else None\n",
    "        plt.plot(domain.x[0],data[time]/normalisation, style, alpha = lalpha, label=lname)\n",
    "                 \n",
    "    if labelx:\n",
    "        plt.xlabel('$x/D$', fontsize=15)\n",
    "    if label:\n",
    "        plt.ylabel(label, fontsize=15)\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    if save_file:\n",
    "        plt.savefig(save_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain = burgers\n",
    "# Set initial condition for 'u'\n",
    "U0=0.25*( 1+np.cos(2*np.pi/ domain.lengths[0]  *(domain.x[0]-0.25)) )\n",
    "Umax = U0.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved_times : [0.  0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1. ]\n"
     ]
    }
   ],
   "source": [
    "burgers.set_dt(dt)\n",
    "end_time_forecast = 1.\n",
    "times = burgers.window(end_time_forecast)\n",
    "saved_times = times[::50]\n",
    "print('saved_times :' ,saved_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "burgers._make_trend_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast = burgers.forecast(times, np.array([U0.reshape((1,)+U0.shape+(1,)) ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for time in times:\n",
    "    plt.plot(domain.x[0], forecast[time][0,0,:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PKF for the Burgers dynamics "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set of the PKF equations for the Burgers equation <a id='burgers-pkf-dyn-pkf'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From Pannekoucke et al. (2018)\n",
    "\n",
    "pkf_dynamics = [\n",
    "    # Trend of the expectation of 'u'\n",
    "    Eq(\n",
    "        Derivative(u,t),\n",
    "        Kappa*Derivative(u,x,2)-u*Derivative(u,x)-Derivative(V,x)/Integer(2)\n",
    "      ),\n",
    "    # Trend of the variance\n",
    "    Eq(\n",
    "        Derivative(V,t),\n",
    "        -Kappa*V/nu + Kappa*Derivative(V,x,2)-Kappa*Derivative(V,x)**Integer(2)/(Integer(2)*V)\n",
    "        -u*Derivative(V,x)-Integer(2)*V*Derivative(u,x)\n",
    "      ),\n",
    "    # Trend of the diffusion\n",
    "    Eq(\n",
    "        Derivative(nu,t),\n",
    "        Integer(4)*Kappa*nu**Integer(2)*closure\n",
    "        -Integer(3)*Kappa*Derivative(nu,x,2)\n",
    "        -Kappa\n",
    "        +Integer(6)*Kappa*Derivative(nu,x)**Integer(2)/nu\n",
    "        -Integer(2)*Kappa*nu*Derivative(V,x,2)/V\n",
    "        +Kappa*Derivative(V,x)*Derivative(nu,x)/V\n",
    "        +Integer(2)*Kappa*nu*Derivative(V,x)**Integer(2)/V**Integer(2)\n",
    "        -u*Derivative(nu,x)\n",
    "        +Integer(2)*nu*Derivative(u,x)\n",
    "    )\n",
    "]\n",
    "\n",
    "display_system(pkf_dynamics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Introduction of the closure ine the PKF dynamics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdenetgen import TrainableScalar\n",
    "\n",
    "# Set the closure by using TrainableScalar\n",
    "a, b, c = [TrainableScalar(l) for l in 'abc']\n",
    "closure_proposal = a*Derivative(nu,x,2)/nu**Integer(2)+b*1/nu**Integer(2)+\\\n",
    "                c*Derivative(nu,x)**2/nu**Integer(3)\n",
    "display(closure_proposal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the closure(t,x) by the proposed closure\n",
    "pkf_dynamics[2] = pkf_dynamics[2].subs(Function('closure')(t,x), closure_proposal)\n",
    "\n",
    "# Generate the NN code leading to the ClosedPKFBurgers class.\n",
    "exec(NNModelBuilder(pkf_dynamics,'ClosedPKFBurgers').code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sample of code generated to define the ClosedPKFBurgers class**\n",
    "```python\n",
    "[..]\n",
    "pow_21 = keras.layers.multiply([div_17,div_17,] ,name='PowLayer_21')\n",
    "mul_28 = keras.layers.multiply([pow_21,Dnu_u_xx_x_o2],name='MulLayer_28')\n",
    "train_scalar_9 = TrainableScalarLayerFactory(input_shape=mul_28.shape, name='TrainableScalar_a', \n",
    "                init_value=0,use_bias=False,mean=0.0,stddev=1.0,seed=None,wl2=None)(mul_28)                \n",
    "                #TrainableScalar name: 'a' \n",
    "add_8 = keras.layers.add([train_scalar_7,train_scalar_8,train_scalar_9],name='AddLayer_8')\n",
    "mul_26 = keras.layers.multiply([pow_17,add_8],name='MulLayer_26')\n",
    "[..]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(NNModelBuilder(pkf_dynamics,'ClosedPKFBurgers').code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Display the closed PKF dynamics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_system(pkf_dynamics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set initial PKF fields**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set initial condition for the variance parameter 'V_u'\n",
    "V0 = (0.01*Umax)**2 + 0*U0\n",
    "\n",
    "# Set the initial condition for the diffusion \n",
    "# L**2 = 2nu t => nu = 0.5*L**2\n",
    "lh = 0.02*domain.lengths[0]\n",
    "nu0 = 0.5*lh**2 + 0*U0\n",
    "\n",
    "state0 = np.asarray([U0, V0,nu0])\n",
    "normalization = {\n",
    "                'Velocity':U0.max(), \n",
    "                'Variance':V0.max(), \n",
    "                'Length-scale':lh\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_scale = lambda nu: np.sqrt(2*nu)\n",
    "plt.figure(figsize=(12,12))\n",
    "for k,field in enumerate(normalization):\n",
    "    plt.subplot(221+k)\n",
    "    if field=='Length-scale':\n",
    "        data = {0:length_scale(state0[k])}\n",
    "    else:\n",
    "        data = {0:state0[k]}\n",
    "    plot_results(data, label=field)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerical application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pkf_traj_ensemble(traj):\n",
    "    plt.figure(figsize=(15,5))\n",
    "    for k,field in enumerate(normalization):\n",
    "        if field=='Length-scale':\n",
    "            data = {time:length_scale(traj[time][k]) for time in traj}\n",
    "        else:\n",
    "            data = {time:traj[time][k] for time in traj}\n",
    "        plt.subplot(131+k)\n",
    "        plot_results(data,label=field,normalisation=normalization[field])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state0 = np.asarray([U0.reshape((1,)+U0.shape+(1,)), \n",
    "                     V0.reshape((1,)+V0.shape+(1,)), \n",
    "                     nu0.reshape((1,)+nu0.shape+(1,))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pkf_traj_NN(traj):\n",
    "    plt.figure(figsize=(15,5))\n",
    "    for k,field in enumerate(normalization):\n",
    "        if field=='Length-scale':\n",
    "            data = {time:length_scale(traj[time][k][0,:,0]) for time in traj}\n",
    "        else:\n",
    "                data = {time:traj[time][k][0,:,0] for time in traj}\n",
    "        plt.subplot(131+k)\n",
    "        plot_results(data,label=field,normalisation=normalization[field])\n",
    "    \n",
    "#plt.savefig(\"./figures/NN-PKF-closure_loc-gaussian.jpg\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation of a database <a id='set-database'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Gaussian random vector of Gaussian correlation function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création d'une matrice de covariance d'erreur de prévision initiale: $P_0$\n",
    "#   Cette matrice est construite comme une matrice homogène de corrélation Gaussienne et de longueur de portée l_h\n",
    "\n",
    "# 1) Définition de la fonction de corrélation homogène\n",
    "gauss = lambda x : np.exp(-0.5*x**2/lh**2) # lh has been previously specified \n",
    "correlation = gauss(domain.x[0]-domain.x[0][domain.shape[0]//2])\n",
    "spectrum = np.abs(np.fft.fft(correlation))\n",
    "\n",
    "# 2) Construction de B^(1/2)\n",
    "std_spectrum = np.sqrt(spectrum)\n",
    "def make_sample():\n",
    "    zeta = np.random.normal(size=domain.shape)\n",
    "    zeta = np.fft.fft(zeta)\n",
    "    ef = np.fft.ifft(std_spectrum * zeta)\n",
    "    ef = np.real(ef)\n",
    "    return ef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "plt.subplot(121)\n",
    "plt.plot(domain.x[0], correlation)\n",
    "plt.title('Homogenous correlation function');\n",
    "plt.subplot(122)\n",
    "for k in range(10):\n",
    "    plt.plot(domain.x[0], make_sample())\n",
    "plt.title(\"Example of sample errors\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Diagnosis tool for ensemble estimation of expectation/variance/diffusion tensor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_init_ensemble(Ne):\n",
    "    return np.array([make_sample() for k in range(Ne)])\n",
    "\n",
    "def estimate_covariance(ensemble):\n",
    "    mean = ensemble.mean(0)\n",
    "    error = (ensemble - mean)/np.sqrt(len(ensemble))\n",
    "    return error.T @ error\n",
    "\n",
    "class EnsembleDiagnosis(object):\n",
    "    \n",
    "    def __init__(self, ensemble, base_space):\n",
    "        self.base_space = base_space\n",
    "        \n",
    "        if isinstance(ensemble, list):\n",
    "            ensemble = np.array(ensemble)\n",
    "        \n",
    "        if len(ensemble.shape)==3:\n",
    "            ensemble = np.array([elm[0] for elm in ensemble])\n",
    "        \n",
    "        # 1) Computation of the mean\n",
    "        self.mean = ensemble.mean(axis=0)\n",
    "        \n",
    "        # 2) Computation of the variance\n",
    "        self.std = ensemble.std(axis=0)\n",
    "        self.variance = self.std*self.std\n",
    "        \n",
    "        # 3) Computation of the metric terms \n",
    "        #  we use the formula g_ij = E[(D_i eps)(D_j eps)]\n",
    "        \n",
    "        #  a) Computation of the normalized error\n",
    "        epsilon = (ensemble-self.mean)/self.std\n",
    "        \n",
    "        #  b) Computation of derivatives\n",
    "        n = self.base_space.shape[0]\n",
    "        K = np.arange(n)\n",
    "        kp = (K+1)%n\n",
    "        km = (K-1)%n\n",
    "        dx = self.base_space.dx[0]\n",
    "        Depsilon = np.array([(eps[kp]-eps[km])/(2*dx) for eps in epsilon])\n",
    "        self.metric = (Depsilon*Depsilon).mean(axis=0)     # see Pannekoucke et al. (2018) for details   \n",
    "        \n",
    "        # Computation of the diffusion tensor\n",
    "        self.diffusion = 0.5*1/self.metric\n",
    "        self.length_scale = np.sqrt(2*self.diffusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Ensemble validation for the covariance setting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ne = 1600\n",
    "\n",
    "ensemble = make_init_ensemble(Ne)\n",
    "\n",
    "mean = ensemble.mean(axis=0)\n",
    "std = ensemble.std(axis=0)\n",
    "\n",
    "print(f\"Validation of the mean (=0): {mean.mean()} +/- {mean.std()}\" )\n",
    "print(f\"Validation of the standard-deviation (=1): {std.mean()} +/- {std.std()}\" )\n",
    "\n",
    "ens_diagnosis = EnsembleDiagnosis(ensemble, domain)\n",
    "nu_h = 0.5*lh**2\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "\n",
    "plt.subplot(131)\n",
    "plt.plot(ens_diagnosis.mean)\n",
    "plt.title('Moyenne')\n",
    "\n",
    "plt.subplot(132)\n",
    "plt.plot(ens_diagnosis.variance)\n",
    "plt.title('Variance')\n",
    "\n",
    "plt.subplot(133)\n",
    "plt.plot(ens_diagnosis.diffusion/nu_h)\n",
    "plt.title('diffusion (normalisée par $nu_h$)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Computation of a large ensemble (1600 members) to build a reference**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard deviation for the initial perturbation\n",
    "sigma_f = 0.01*U0.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters for ensemble estimation\n",
    "large_Ne = 1600\n",
    "\n",
    "# 1. Set the initial background state\n",
    "random_U0 = U0 + sigma_f*make_init_ensemble(1)[0]\n",
    "\n",
    "# 2. Build an ensemble of initial perturbed state\n",
    "ensemble = make_init_ensemble(large_Ne)\n",
    "ensemble_ea = np.array([random_U0+sigma_f*ea for ea in ensemble])\n",
    "ensemble_ea = ensemble_ea.reshape((1,)+ensemble_ea.shape+(1,))\n",
    "print(f\"shape of ensemble_ea: {ensemble_ea.shape}\")\n",
    "\n",
    "# 3. Build the ensemble of forecast using the NN architecture\n",
    "ensemble_forecast = burgers.forecast(times,ensemble_ea)\n",
    "\n",
    "# 4. Compute diagnosis from ensemble\n",
    "ensemble_traj = {}\n",
    "for time in times[::50]:\n",
    "    diagnosis = EnsembleDiagnosis(ensemble_forecast[time][0,:,:,0], domain)\n",
    "    ensemble_traj[time] = [diagnosis.mean, diagnosis.variance, diagnosis.diffusion]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pkf_traj_ensemble(ensemble_traj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Generation of the training data set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(k, Ne=400):\n",
    "    # 1. Set the initial background state\n",
    "    random_U0 = U0 + sigma_f*make_init_ensemble(1)[0]\n",
    "\n",
    "    # 2. Build an ensemble of initial perturbed state\n",
    "    ensemble = make_init_ensemble(Ne)\n",
    "    ensemble_ea = np.array([random_U0+sigma_f*ea for ea in ensemble])\n",
    "    ensemble_ea = ensemble_ea.reshape((1,)+ensemble_ea.shape+(1,))    \n",
    "        \n",
    "    # 3. Compute the ensemble of forecasts\n",
    "    ensemble_forecast = burgers.forecast(times,ensemble_ea)\n",
    "\n",
    "    # 4. Compute the diagnosis    \n",
    "    diagnosis_list = []\n",
    "    for time in times:\n",
    "        diagnosis = EnsembleDiagnosis(ensemble_forecast[time][0,:,:,0], domain)\n",
    "        diagnosis_list.append( np.array([diagnosis.mean, diagnosis.variance, diagnosis.diffusion]))\n",
    "        \n",
    "    return diagnosis_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_size = 400  # for Ne=400, this takes 1h09'01'' so take care with this..\n",
    "save_file = \"pkf-dataset.npy\"\n",
    "\n",
    "generate_data_set = False\n",
    "parallel_diagnosis = False\n",
    "    \n",
    "try:\n",
    "    # load data\n",
    "    data = np.load(save_file)\n",
    "    data = data.reshape(data.shape+(1,))\n",
    "except:\n",
    "    # 1. Generate data   \n",
    "    #data = [generate_data(k) for k in range(data_size)]\n",
    "    data = []\n",
    "    for k in range(data_size):\n",
    "        if k%5==0:\n",
    "            print(k)\n",
    "        data.append(generate_data(k))\n",
    "    \n",
    "\n",
    "    # 2. Save data\n",
    "    data = np.array(data)\n",
    "    np.save(save_file,data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training of the closure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Make a RK4 time scheme**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_time_scheme(dt, trend):\n",
    "    \"\"\" Implementation of an RK4 with Keras \"\"\"\n",
    "    \n",
    "    state = keras.layers.Input(shape = trend.input_shape[1:])\n",
    "    \n",
    "    # k1 \n",
    "    k1 = trend(state)\n",
    "    # k2 \n",
    "    _tmp_1 = keras.layers.Lambda(lambda x : 0.5*dt*x)(k1)\n",
    "    input_k2 = keras.layers.add([state,_tmp_1])\n",
    "    k2 = trend(input_k2)\n",
    "    # k3 \n",
    "    _tmp_2 = keras.layers.Lambda(lambda x : 0.5*dt*x)(k2)\n",
    "    input_k3 = keras.layers.add([state,_tmp_2])\n",
    "    k3 = trend(input_k3)\n",
    "    # k4 \n",
    "    _tmp_3 = keras.layers.Lambda(lambda x : dt*x)(k3)\n",
    "    input_k4 = keras.layers.add([state,_tmp_3])\n",
    "    k4 = trend(input_k4)\n",
    "    \n",
    "    # output\n",
    "    # k2+k3\n",
    "    add_k2_k3 = keras.layers.add([k2,k3])\n",
    "    add_k2_k3_mul2 = keras.layers.Lambda(lambda x:2.*x)(add_k2_k3)\n",
    "    # Add k1,k4\n",
    "    _sum = keras.layers.add([k1,add_k2_k3_mul2,k4])\n",
    "    # *dt\n",
    "    _sc_mul = keras.layers.Lambda(lambda x:dt/6.*x)(_sum)\n",
    "    output = keras.layers.add([state, _sc_mul])\n",
    "    \n",
    "    time_scheme = keras.models.Model(inputs =[state], \n",
    "                                     outputs=[output])\n",
    "    return time_scheme "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closed_pkf_burgers = ClosedPKFBurgers(shape=(241,),kappa=kappa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closed_pkf_burgers._make_dynamical_trend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_scheme = make_time_scheme(dt, closed_pkf_burgers._dynamical_trend)\n",
    "#time_scheme.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closed_pkf_burgers._dynamical_trend.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Constitution de la base de données d'apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_from = 400 # 200\n",
    "X = np.array([elm[select_from:-1] for elm in data])\n",
    "Y = np.array([elm[select_from+1:] for elm in data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.reshape((np.prod(X.shape[:2]),3,241,1))\n",
    "Y = Y.reshape((np.prod(Y.shape[:2]),3,241,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Training of the NN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closed_pkf_burgers._trend_model.get_layer('TrainableScalar_a').get_weights()[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value of the unknowns (a,b,c) before the training\n",
    "untrained = []\n",
    "for l in \"abc\":\n",
    "    untrained.append(float(closed_pkf_burgers._trend_model.get_layer('TrainableScalar_'+l).get_weights()[0]))\n",
    "    print(f\"{l}: {untrained[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closed_pkf_burgers._dynamical_trend.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expérience d'apprentissage:\n",
    "# 2. Adam\n",
    "lr = 0.1 \n",
    "epochs = 30\n",
    "\n",
    "for iteration in range(3):\n",
    "    # 1. Set the learning\n",
    "    time_scheme.compile(optimizer=keras.optimizers.Adam(lr=lr),\n",
    "        loss='mean_squared_error') \n",
    "    \n",
    "    # 2. Train\n",
    "    history = time_scheme.fit(X,Y,epochs=epochs, batch_size=32,verbose=0)\n",
    "    print(f\"iteration {iteration} is complet\")\n",
    "    \n",
    "    # 3. Plot history    \n",
    "    plt.figure()\n",
    "    plt.plot(history.history['loss'])\n",
    "    \n",
    "    # 4. Update the learning rate for next iteration\n",
    "    lr = lr/10\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison with the theoretically designed closure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compare the weights with the previous theoretical closure**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#closed_pkf_burgers._trend_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained = []\n",
    "for l in \"abc\":\n",
    "    trained.append(float(closed_pkf_burgers._trend_model.get_layer('TrainableScalar_'+l).get_weights()[0]))\n",
    "    print(f\"{l}: {trained[-1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weights of the theoretical closure are : 1, 3/4, -2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained = np.array((trained[0], trained[1], trained[2])).flatten()\n",
    "trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theoretical = np.array([1,3/4,-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_error = (trained - theoretical)/theoretical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_error*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exemple de prévision réalisée avec le modèle calibré**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default\n",
    "closed_pkf_burgers.set_dt(dt)\n",
    "times = closed_pkf_burgers.window(1)\n",
    "saved_times = times[::50]\n",
    "print('saved_times :' ,saved_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_unclosed_traj = closed_pkf_burgers.forecast(times, state0, saved_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PKF using trained closure\n",
    "plot_pkf_traj_NN(trained_unclosed_traj)\n",
    "plt.savefig('./figures/burgers-TrainableScalar-b.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensemble of forecast statistics\n",
    "plot_pkf_traj_ensemble(ensemble_traj)\n",
    "plt.savefig('./figures/burgers-TrainableScalar-a.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion <a id='conclusion'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we have considered the uncertainty prediction for the Burgers dynamics where an unclosed term is present.\n",
    "\n",
    "A closure has been proposed and implemented as **a symbolic expression where unknown quantities are defined as `TrainableScalar`**\n",
    "which are translated into a trainable neural network.\n",
    "\n",
    "A synthetic dataset has been used to train the NN. The resulting closure has shown to be relevant to predict the uncertainty."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "nav_menu": {
    "height": "244px",
    "width": "212px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
