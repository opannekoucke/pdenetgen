{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1><center> Training of a closure for the uncertainty ropagation in the Burgers equation</center></h1>\n",
    "<center>\n",
    "    Olivier Pannekoucke <br>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "<div class=\"math abstract\">\n",
    "    <p style=\"text-align:center\"><b>Abstract</b></p>\n",
    "    <p>\n",
    "    Estimation of the closure for the uncertainty propagation in the Burgers dynamics\n",
    "    </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "---\n",
    "<center> <b>Table of contents</b> </center>\n",
    "\n",
    " 1. [Introduction](#introduction)\n",
    " 1. [The Burgers dynamics and its unclosed PKF formulation](#burgers-pkf)\n",
    "  1. [Set of the function and symbols](#burgers-pkf-sympy-definition)\n",
    "  1. [Set constants for numerical experiments](#burgers-pkf-num-definition)\n",
    "  1. [Set of the Burgers equation](#burgers-pkf-dyn-burgers)\n",
    "  1. [Set of the PKF equations for the Burgers equation](#burgers-pkf-dyn-PKF)\n",
    " 1. [Application numerique](#num)\n",
    "  1. [Définition et utilisation de la dynamique fermée](#num-closed)\n",
    "  1. [Définition et apprentissage de la dynamique non-fermée](#num-unclosed)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-29T13:49:35.003934Z",
     "start_time": "2018-11-29T13:49:34.831778Z"
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib inline\n",
    "#%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction <a id='introduction'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim is to design a NN which merges known and unknown physics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-03T09:05:22.911943Z",
     "start_time": "2018-10-03T09:05:22.699109Z"
    }
   },
   "outputs": [],
   "source": [
    "import sympy\n",
    "from sympy import (Function, symbols, init_printing, Derivative, \n",
    "                   latex, Add, Mul, Pow, \n",
    "                   Integer, Rational, Float, Symbol, symbol,\n",
    "                   srepr, Tuple\n",
    "                  )\n",
    "init_printing() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(data, label=None, labelx=True, title=None, save_file=None, normalisation=None, \n",
    "                 selected_times=None,style=None, name=None, alpha=1., bolds=[0., 1.]):\n",
    "    \n",
    "    normalisation = 1. if normalisation is None else normalisation\n",
    "                 \n",
    "    selected_times = [time for time in data] if selected_times is None else selected_times\n",
    "                 \n",
    "    style = 'k' if style is None else style\n",
    "                 \n",
    "    for time in selected_times:\n",
    "        lalpha = alpha if time in bolds else 0.2\n",
    "        lname = name if time==selected_times[-1] else None\n",
    "        plt.plot(domain.x[0],data[time]/normalisation, style, alpha = lalpha, label=lname)\n",
    "                 \n",
    "    if labelx:\n",
    "        plt.xlabel('$x/D$', fontsize=15)\n",
    "    if label:\n",
    "        plt.ylabel(label, fontsize=15)\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    if save_file:\n",
    "        plt.savefig(save_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Burgers dynamics and its unclosed PKF formulation <a id='burgers-pkf'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdenetgen import NNModelBuilder, Eq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_system(system):\n",
    "    print(50*'*')\n",
    "    for equation in system:\n",
    "        display(equation)\n",
    "        print(50*'*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set of the function and symbols <a id='burgers-pkf-sympy-definition'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t, x = symbols('t x')\n",
    "\n",
    "u = Function('u')(t,x)\n",
    "closure = sympy.Function('closure')(t,x)\n",
    "V = Function('{V_{u}}')(t,x)\n",
    "nu = Function('{\\\\nu_{u,xx}}')(t,x)\n",
    "Kappa = symbols('\\\\kappa')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set constants for numerical experiments <a id='burgers-pkf-num-definition'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constant setting following Pannekoucke et al. (2018)\n",
    "n = 241\n",
    "kappa = 0.0025\n",
    "dt = 0.002"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set of the Burgers equation <a id='burgers-pkf-dyn-burgers'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "burgers_dynamics = [\n",
    "        Eq(\n",
    "        Derivative(u,t),\n",
    "        Kappa*Derivative(u,x,2)-u*Derivative(u,x)\n",
    "      ),\n",
    "]\n",
    "display_system(burgers_dynamics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "burgers_NN_builder = NNModelBuilder(burgers_dynamics, \"Burgers\")\n",
    "print(burgers_NN_builder.code)\n",
    "exec(burgers_NN_builder.code)\n",
    "burgers = Burgers(shape=(n,), kappa=kappa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Example of forecast from a given initial condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain = burgers\n",
    "# Set initial condition for 'u'\n",
    "U0=0.25*( 1+np.cos(2*np.pi/ domain.lengths[0]  *(domain.x[0]-0.25)) )\n",
    "Umax = U0.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "burgers.set_dt(dt)\n",
    "end_time_forecast = 1.\n",
    "times = burgers.window(end_time_forecast)\n",
    "saved_times = times[::50]\n",
    "print('saved_times :' ,saved_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast = burgers.forecast(times, np.array([U0.reshape((1,)+U0.shape+(1,)) ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for time in times:\n",
    "    plt.plot(domain.x[0], forecast[time][0,0,:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set of the PKF equations for the Burgers equation <a id='burgers-pkf-dyn-pkf'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From Pannekoucke et al. (2018)\n",
    "\n",
    "pkf_dynamics = [\n",
    "    # Trend of the expectation of 'u'\n",
    "    Eq(\n",
    "        Derivative(u,t),\n",
    "        Kappa*Derivative(u,x,2)-u*Derivative(u,x)-Derivative(V,x)/Integer(2)\n",
    "      ),\n",
    "    # Trend of the variance\n",
    "    Eq(\n",
    "        Derivative(V,t),\n",
    "        -Kappa*V/nu + Kappa*Derivative(V,x,2)-Kappa*Derivative(V,x)**Integer(2)/(Integer(2)*V)\n",
    "        -u*Derivative(V,x)-Integer(2)*V*Derivative(u,x)\n",
    "      ),\n",
    "    # Trend of the diffusion\n",
    "    Eq(\n",
    "        Derivative(nu,t),\n",
    "        Integer(4)*Kappa*nu**Integer(2)*closure\n",
    "        -Integer(3)*Kappa*Derivative(nu,x,2)\n",
    "        -Kappa\n",
    "        +Integer(6)*Kappa*Derivative(nu,x)**Integer(2)/nu\n",
    "        -Integer(2)*Kappa*nu*Derivative(V,x,2)/V\n",
    "        +Kappa*Derivative(V,x)*Derivative(nu,x)/V\n",
    "        +Integer(2)*Kappa*nu*Derivative(V,x)**Integer(2)/V**Integer(2)\n",
    "        -u*Derivative(nu,x)\n",
    "        +Integer(2)*nu*Derivative(u,x)\n",
    "    )\n",
    "]\n",
    "\n",
    "display_system(pkf_dynamics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkf_NN_builder = NNModelBuilder(pkf_dynamics,'NN_Unclosed_PKF_Burgers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pkf_NN_builder.code)\n",
    "exec(pkf_NN_builder.code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construction of a closure as a NN from parameterized form"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='math philo'>\n",
    "  <p>\n",
    "  L'objectif est de calculer le terme\n",
    "  $$a\\frac{\\frac{\\partial^{2}}{\\partial x^{2}} \\operatorname{{\\nu_{u,xx}}}{\\left(t,x \\right)}}{\\operatorname{{\\nu_{u,xx}}}^{2}{\\left(t,x \\right)}} +b \\frac{1}{ \\operatorname{{\\nu_{u,xx}}}^{2}{\\left(t,x \\right)}} +c\\frac{ \\left(\\frac{\\partial}{\\partial x} \\operatorname{{\\nu_{u,xx}}}{\\left(t,x \\right)}\\right)^{2}}{\\operatorname{{\\nu_{u,xx}}}^{3}{\\left(t,x \\right)}},$$\n",
    "  sous la forme d'une fonction exogène.\n",
    "  </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClosedPKFBurgers(NN_Unclosed_PKF_Burgers):\n",
    "    def _make_exogenous_model(self):\n",
    "                \n",
    "        u = keras.layers.Input(shape=(self.input_shape_x,1))\n",
    "        V = keras.layers.Input(shape=(self.input_shape_x,1))\n",
    "        nu_u_xx = keras.layers.Input(shape=(self.input_shape_x,1))        \n",
    "        \n",
    "        #\n",
    "        # Computation of the spatial derivatives\n",
    "        #\n",
    "        \n",
    "        kernel_Dnu_u_xx_x_o2 = np.asarray([self.dx[self.coordinates.index('x')]**(-2),\n",
    "        -2/self.dx[self.coordinates.index('x')]**2,\n",
    "        self.dx[self.coordinates.index('x')]**(-2)]).reshape((3,)+(1,1))\n",
    "        Dnu_u_xx_x_o2 = DerivativeFactory((3,),kernel=kernel_Dnu_u_xx_x_o2,name='Dnu_u_xx_x_o2')(nu_u_xx)\n",
    "        \n",
    "        kernel_Dnu_u_xx_x_o1 = np.asarray([-1/(2*self.dx[self.coordinates.index('x')]),0.0,\n",
    "        1/(2*self.dx[self.coordinates.index('x')])]).reshape((3,)+(1,1))\n",
    "        Dnu_u_xx_x_o1 = DerivativeFactory((3,),kernel=kernel_Dnu_u_xx_x_o1,name='Dnu_u_xx_x_o1')(nu_u_xx)        \n",
    "        \n",
    "        #\n",
    "        # Design of the unknown closure to train\n",
    "        #\n",
    "        \n",
    "        # Terme 1\n",
    "        div_14 = keras.layers.Lambda(lambda x: 1/x,name='DivLayer_14')(nu_u_xx)\n",
    "        pow_12 = keras.layers.multiply([div_14,div_14,] ,name='PowLayer_12')\n",
    "        term1 = keras.layers.multiply([pow_12,Dnu_u_xx_x_o2],name='MulLayer_25')\n",
    "        \n",
    "        # Terme 2\n",
    "        div_13 = keras.layers.Lambda(lambda x: 1/x,name='DivLayer_13')(nu_u_xx)\n",
    "        term2 = keras.layers.multiply([div_13,div_13,] ,name='PowLayer_11')\n",
    "        \n",
    "        # Terme 3\n",
    "        pow_13 = keras.layers.multiply([Dnu_u_xx_x_o1,Dnu_u_xx_x_o1,] ,name='PowLayer_13')\n",
    "        div_15 = keras.layers.Lambda(lambda x: 1/x,name='DivLayer_15')(nu_u_xx)\n",
    "        pow_14 = keras.layers.multiply([div_15,div_15,div_15,] ,name='PowLayer_14')\n",
    "        term3 = keras.layers.multiply([pow_13,pow_14],name='MulLayer_26')\n",
    "        \n",
    "        # Product by (a,b,c), implemented as Conv1D\n",
    "        term1 = keras.layers.Conv1D(1,1,name='times_a',padding='same',use_bias=False,activation='linear')(term1)\n",
    "        term2 = keras.layers.Conv1D(1,1,name='times_b',padding='same',use_bias=False,activation='linear')(term2)\n",
    "        term3 = keras.layers.Conv1D(1,1,name='times_c',padding='same',use_bias=False,activation='linear')(term3)\n",
    "                \n",
    "        closure = keras.layers.add([term1, term2, term3],name='Closure')        \n",
    "                \n",
    "        self._exogenous_model = keras.models.Model(inputs=[u,V,nu_u_xx], outputs=[closure])\n",
    "        \n",
    "    def compute_exogenous(self, t, state):\n",
    "        \n",
    "        if self._exogenous_model is None:\n",
    "            self._make_exogenous_model()\n",
    "        \n",
    "        u,V,nu = state\n",
    "        closure = self._exogenous_model.predict([u,V,nu])\n",
    "        if not isinstance(closure, list):\n",
    "            closure = [closure]\n",
    "        return closure\n",
    "        \n",
    "    def _make_full_trend(self):\n",
    "        \n",
    "        if self._trend_model is None:\n",
    "            self._make_trend_model()\n",
    "        if self._exogenous_model is None:\n",
    "            self._make_exogenous_model()\n",
    "        \n",
    "        state = keras.layers.Input(shape=(3,self.input_shape_x,1))\n",
    "        \n",
    "        u = keras.layers.Lambda(lambda x : x[:,0,:,:])(state)\n",
    "        V = keras.layers.Lambda(lambda x : x[:,1,:,:])(state)\n",
    "        nu_u_xx = keras.layers.Lambda(lambda x : x[:,2,:,:])(state)\n",
    "        \n",
    "        closure = self._exogenous_model([u,V,nu_u_xx])\n",
    "        trend_u, trend_V, trend_nu = self._trend_model([u,V,nu_u_xx,closure])\n",
    "        \n",
    "        trend_u = keras.layers.Reshape((1,self.input_shape_x,1))(trend_u)\n",
    "        trend_V = keras.layers.Reshape((1,self.input_shape_x,1))(trend_V)\n",
    "        trend_nu = keras.layers.Reshape((1,self.input_shape_x,1))(trend_nu)\n",
    "        \n",
    "        trend = keras.layers.Concatenate(axis=1)([trend_u,trend_V,trend_nu])\n",
    "        self._full_trend = keras.models.Model(inputs=state,outputs=trend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closed_burgers = ClosedPKFBurgers(shape=(241,),kappa=kappa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closed_burgers._make_full_trend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set initial PKF fields**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set initial condition for the variance parameter 'V_u'\n",
    "V0 = (0.01*Umax)**2 + 0*U0\n",
    "\n",
    "# Set the initial condition for the diffusion \n",
    "# L**2 = 2nu t => nu = 0.5*L**2\n",
    "lh = 0.02*domain.lengths[0]\n",
    "nu0 = 0.5*lh**2 + 0*U0\n",
    "\n",
    "state0 = np.asarray([U0, V0,nu0])\n",
    "normalization = {\n",
    "                'Velocity':U0.max(), \n",
    "                'Variance':V0.max(), \n",
    "                'Length-scale':lh\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_scale = lambda nu: np.sqrt(2*nu)\n",
    "plt.figure(figsize=(12,12))\n",
    "for k,field in enumerate(normalization):\n",
    "    plt.subplot(221+k)\n",
    "    if field=='Length-scale':\n",
    "        data = {0:length_scale(state0[k])}\n",
    "    else:\n",
    "        data = {0:state0[k]}\n",
    "    plot_results(data, label=field)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application numérique <a id='num'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pkf_traj_ensemble(traj):\n",
    "    plt.figure(figsize=(15,5))\n",
    "    for k,field in enumerate(normalization):\n",
    "        if field=='Length-scale':\n",
    "            data = {time:length_scale(traj[time][k]) for time in traj}\n",
    "        else:\n",
    "            data = {time:traj[time][k] for time in traj}\n",
    "        plt.subplot(131+k)\n",
    "        plot_results(data,label=field,normalisation=normalization[field])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Définition et utilisation de la dynamique fermée <a id='num-closed'/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state0 = np.asarray([U0.reshape((1,)+U0.shape+(1,)), \n",
    "                     V0.reshape((1,)+V0.shape+(1,)), \n",
    "                     nu0.reshape((1,)+nu0.shape+(1,))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pkf_traj_NN(traj):\n",
    "    plt.figure(figsize=(15,5))\n",
    "    for k,field in enumerate(normalization):\n",
    "        if field=='Length-scale':\n",
    "            data = {time:length_scale(traj[time][k][0,:,0]) for time in traj}\n",
    "        else:\n",
    "                data = {time:traj[time][k][0,:,0] for time in traj}\n",
    "        plt.subplot(131+k)\n",
    "        plot_results(data,label=field,normalisation=normalization[field])\n",
    "    \n",
    "#plt.savefig(\"./figures/NN-PKF-closure_loc-gaussian.jpg\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation of a database <a id='set-database'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Gaussian random vector of Gaussian correlation function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création d'une matrice de covariance d'erreur de prévision initiale: $P_0$\n",
    "#   Cette matrice est construite comme une matrice homogène de corrélation Gaussienne et de longueur de portée l_h\n",
    "\n",
    "# 1) Définition de la fonction de corrélation homogène\n",
    "gauss = lambda x : np.exp(-0.5*x**2/lh**2) # lh has been previously specified \n",
    "correlation = gauss(domain.x[0]-domain.x[0][domain.shape[0]//2])\n",
    "spectrum = np.abs(np.fft.fft(correlation))\n",
    "\n",
    "# 2) Construction de B^(1/2)\n",
    "std_spectrum = np.sqrt(spectrum)\n",
    "def make_sample():\n",
    "    zeta = np.random.normal(size=domain.shape)\n",
    "    zeta = np.fft.fft(zeta)\n",
    "    ef = np.fft.ifft(std_spectrum * zeta)\n",
    "    ef = np.real(ef)\n",
    "    return ef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "plt.subplot(121)\n",
    "plt.plot(domain.x[0], correlation)\n",
    "plt.title('Homogenous correlation function');\n",
    "plt.subplot(122)\n",
    "for k in range(10):\n",
    "    plt.plot(domain.x[0], make_sample())\n",
    "plt.title(\"Example of sample errors\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Diagnosis tool for ensemble estimation of expectation/variance/diffusion tensor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_init_ensemble(Ne):\n",
    "    return np.array([make_sample() for k in range(Ne)])\n",
    "\n",
    "def estimate_covariance(ensemble):\n",
    "    mean = ensemble.mean(0)\n",
    "    error = (ensemble - mean)/np.sqrt(len(ensemble))\n",
    "    return error.T @ error\n",
    "\n",
    "class EnsembleDiagnosis(object):\n",
    "    \n",
    "    def __init__(self, ensemble, base_space):\n",
    "        self.base_space = base_space\n",
    "        \n",
    "        if isinstance(ensemble, list):\n",
    "            ensemble = np.array(ensemble)\n",
    "        \n",
    "        if len(ensemble.shape)==3:\n",
    "            ensemble = np.array([elm[0] for elm in ensemble])\n",
    "        \n",
    "        # 1) Computation of the mean\n",
    "        self.mean = ensemble.mean(axis=0)\n",
    "        \n",
    "        # 2) Computation of the variance\n",
    "        self.std = ensemble.std(axis=0)\n",
    "        self.variance = self.std*self.std\n",
    "        \n",
    "        # 3) Computation of the metric terms \n",
    "        #  we use the formula g_ij = E[(D_i eps)(D_j eps)]\n",
    "        \n",
    "        #  a) Computation of the normalized error\n",
    "        epsilon = (ensemble-self.mean)/self.std\n",
    "        \n",
    "        #  b) Computation of derivatives\n",
    "        n = self.base_space.shape[0]\n",
    "        K = np.arange(n)\n",
    "        kp = (K+1)%n\n",
    "        km = (K-1)%n\n",
    "        dx = self.base_space.dx[0]\n",
    "        Depsilon = np.array([(eps[kp]-eps[km])/(2*dx) for eps in epsilon])\n",
    "        self.metric = (Depsilon*Depsilon).mean(axis=0)     # see Pannekoucke et al. (2018) for details   \n",
    "        \n",
    "        # Computation of the diffusion tensor\n",
    "        self.diffusion = 0.5*1/self.metric\n",
    "        self.length_scale = np.sqrt(2*self.diffusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Ensemble validation for the covariance setting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ne = 1600\n",
    "\n",
    "ensemble = make_init_ensemble(Ne)\n",
    "\n",
    "mean = ensemble.mean(axis=0)\n",
    "std = ensemble.std(axis=0)\n",
    "\n",
    "print(f\"Validation of the mean (=0): {mean.mean()} +/- {mean.std()}\" )\n",
    "print(f\"Validation of the standard-deviation (=1): {std.mean()} +/- {std.std()}\" )\n",
    "\n",
    "ens_diagnosis = EnsembleDiagnosis(ensemble, domain)\n",
    "nu_h = 0.5*lh**2\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "\n",
    "plt.subplot(131)\n",
    "plt.plot(ens_diagnosis.mean)\n",
    "plt.title('Moyenne')\n",
    "\n",
    "plt.subplot(132)\n",
    "plt.plot(ens_diagnosis.variance)\n",
    "plt.title('Variance')\n",
    "\n",
    "plt.subplot(133)\n",
    "plt.plot(ens_diagnosis.diffusion/nu_h)\n",
    "plt.title('diffusion (normalisée par $nu_h$)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Computation of a large ensemble (1600 members) to build a reference**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard deviation for the initial perturbation\n",
    "sigma_f = 0.01*U0.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters for ensemble estimation\n",
    "large_Ne = 1600\n",
    "\n",
    "# 1. Set the initial background state\n",
    "random_U0 = U0 + sigma_f*make_init_ensemble(1)[0]\n",
    "\n",
    "# 2. Build an ensemble of initial perturbed state\n",
    "ensemble = make_init_ensemble(large_Ne)\n",
    "ensemble_ea = np.array([random_U0+sigma_f*ea for ea in ensemble])\n",
    "ensemble_ea = ensemble_ea.reshape((1,)+ensemble_ea.shape+(1,))\n",
    "print(f\"shape of ensemble_ea: {ensemble_ea.shape}\")\n",
    "\n",
    "# 3. Build the ensemble of forecast using the NN architecture\n",
    "ensemble_forecast = burgers.forecast(times,ensemble_ea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Compute diagnosis from ensemble\n",
    "ensemble_traj = {}\n",
    "for time in times[::50]:\n",
    "    diagnosis = EnsembleDiagnosis(ensemble_forecast[time][0,:,:,0], domain)\n",
    "    ensemble_traj[time] = [diagnosis.mean, diagnosis.variance, diagnosis.diffusion]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pkf_traj_ensemble(ensemble_traj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Generation of the training data set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(k, Ne=400):\n",
    "    # 1. Set the initial background state\n",
    "    random_U0 = U0 + sigma_f*make_init_ensemble(1)[0]\n",
    "\n",
    "    # 2. Build an ensemble of initial perturbed state\n",
    "    ensemble = make_init_ensemble(Ne)\n",
    "    ensemble_ea = np.array([random_U0+sigma_f*ea for ea in ensemble])\n",
    "    ensemble_ea = ensemble_ea.reshape((1,)+ensemble_ea.shape+(1,))    \n",
    "        \n",
    "    # 3. Compute the ensemble of forecasts\n",
    "    ensemble_forecast = burgers.forecast(times,ensemble_ea)\n",
    "\n",
    "    # 4. Compute the diagnosis    \n",
    "    diagnosis_list = []\n",
    "    for time in times:\n",
    "        diagnosis = EnsembleDiagnosis(ensemble_forecast[time][0,:,:,0], domain)\n",
    "        diagnosis_list.append( np.array([diagnosis.mean, diagnosis.variance, diagnosis.diffusion]))\n",
    "        \n",
    "    return diagnosis_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_size = 400  # for Ne=400, this takes 1h09'01'' so take care with this..\n",
    "save_file = \"pkf-dataset.npy\"\n",
    "\n",
    "generate_data_set = False\n",
    "parallel_diagnosis = False\n",
    "    \n",
    "try:\n",
    "    # load data\n",
    "    data = np.load(save_file)\n",
    "    data = data.reshape(data.shape+(1,))\n",
    "except:\n",
    "    # 1. Generate data   \n",
    "    #data = [generate_data(k) for k in range(data_size)]\n",
    "    data = []\n",
    "    for k in range(data_size):\n",
    "        if k%5==0:\n",
    "            print(k)\n",
    "        data.append(generate_data(k))\n",
    "    \n",
    "\n",
    "    # 2. Save data\n",
    "    data = np.array(data)\n",
    "    np.save(save_file,data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_data():\n",
    "    plt.figure(figsize=(15,5))\n",
    "\n",
    "    title = ['Ensemble mean','Variance','Diffusion']\n",
    "    normalization = [1, sigma_f**2, 0.5*lh**2]\n",
    "\n",
    "    for trajectory in data[:10]:\n",
    "        for date in  trajectory[::100]:    \n",
    "            for k,field in enumerate(date):\n",
    "                plt.subplot(131+k)\n",
    "                plt.plot(domain.x[0], field/normalization[k] )\n",
    "                plt.title(title[k])\n",
    "    plt.savefig('./figures/NN-burgers-training-data.pdf')\n",
    "plot_training_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construction d'un schéma d'intégration RK4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schéma temporelle de type RK4\n",
    "def make_time_scheme(dt, trend):\n",
    "    \"\"\" Implémentation d'un schéma de RK4 sous forme de réseau de neurones \"\"\"\n",
    "    import keras\n",
    "    \n",
    "    state = keras.layers.Input(shape = trend.input_shape[1:])\n",
    "    \n",
    "    # k1 \n",
    "    k1 = trend(state)\n",
    "    # k2 \n",
    "    _tmp_1 = keras.layers.Lambda(lambda x : 0.5*dt*x)(k1)\n",
    "    input_k2 = keras.layers.add([state,_tmp_1])\n",
    "    k2 = trend(input_k2)\n",
    "    # k3 \n",
    "    _tmp_2 = keras.layers.Lambda(lambda x : 0.5*dt*x)(k2)\n",
    "    input_k3 = keras.layers.add([state,_tmp_2])\n",
    "    k3 = trend(input_k3)\n",
    "    # k4 \n",
    "    _tmp_3 = keras.layers.Lambda(lambda x : dt*x)(k3)\n",
    "    input_k4 = keras.layers.add([state,_tmp_3])\n",
    "    k4 = trend(input_k4)\n",
    "    \n",
    "    # output\n",
    "    # k2+k3\n",
    "    add_k2_k3 = keras.layers.add([k2,k3])\n",
    "    add_k2_k3_mul2 = keras.layers.Lambda(lambda x:2.*x)(add_k2_k3)\n",
    "    # Add k1,k4\n",
    "    _sum = keras.layers.add([k1,add_k2_k3_mul2,k4])\n",
    "    # *dt\n",
    "    _sc_mul = keras.layers.Lambda(lambda x:dt/6.*x)(_sum)\n",
    "    output = keras.layers.add([state, _sc_mul])\n",
    "    \n",
    "    time_scheme = keras.models.Model(inputs =[state], outputs=[output])\n",
    "    return time_scheme "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closed_pkf_burgers = ClosedPKFBurgers(shape=(241,),kappa=kappa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closed_pkf_burgers._make_full_trend()\n",
    "closed_pkf_burgers._full_trend.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closed_pkf_burgers._exogenous_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_scheme = make_time_scheme(dt, closed_pkf_burgers._full_trend)\n",
    "#time_scheme.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Constitution de la base de données d'apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_from = 400 # 200\n",
    "X = np.array([elm[select_from:-1] for elm in data])\n",
    "Y = np.array([elm[select_from+1:] for elm in data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.reshape((np.prod(X.shape[:2]),3,241,1))\n",
    "Y = Y.reshape((np.prod(Y.shape[:2]),3,241,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Training of the NN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expérience d'apprentissage:\n",
    "# 2. Adam\n",
    "lr = 0.1 # old value: 0.001\n",
    "epochs = 30\n",
    "\n",
    "for iteration in range(3):\n",
    "    # 1. Set the learning\n",
    "    time_scheme.compile(optimizer=keras.optimizers.Adam(lr=lr),\n",
    "        loss='mean_squared_error') # Ne permet pas la convergence\n",
    "    \n",
    "    # 2. Train\n",
    "    history = time_scheme.fit(X,Y,epochs=epochs, batch_size=32,verbose=0)\n",
    "    print(f\"iteration {iteration} is complet\")\n",
    "    \n",
    "    # 3. Plot history    \n",
    "    plt.figure()\n",
    "    plt.plot(history.history['loss'])\n",
    "    \n",
    "    # 4. Update the learning rate for next iteration\n",
    "    lr = lr/10\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compare the weights with the previous theoretical closure**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weights of the theoretical closure are : 1, 3/4, -2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained = unclosed_burgers._full_trend.get_weights()\n",
    "trained = np.array((trained[0], trained[1], trained[2])).flatten()\n",
    "trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theoretical = np.array([1,3/4,-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_error = (trained - theoretical)/theoretical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_error*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exemple de prévision réalisée avec le modèle calibré**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default\n",
    "unclosed_burgers.set_dt(dt)\n",
    "times = unclosed_burgers.window(1)\n",
    "#saved_times = times[::25]\n",
    "saved_times = times[::50]\n",
    "print('saved_times :' ,saved_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_unclosed_traj = unclosed_burgers.forecast(times, state0, saved_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PKF using trained closure\n",
    "plot_pkf_traj_NN(trained_unclosed_traj)\n",
    "plt.savefig('./figures/burgers-b.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensemble of forecast statistics\n",
    "plot_pkf_traj_ensemble(ensemble_traj)\n",
    "plt.savefig('./figures/burgers-a.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion <a id='conclusion'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='math conclusion'>\n",
    "    In this notebook, a closure for the Burgers dynamics has been learned from the data. \n",
    "    </div>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-28T10:24:45.947541Z",
     "start_time": "2018-11-28T10:24:45.935571Z"
    },
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "with open(\"css/lecture.css\",'r') as css_file:\n",
    "    css_style = css_file.read()\n",
    "HTML(css_style)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "nav_menu": {
    "height": "244px",
    "width": "212px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
